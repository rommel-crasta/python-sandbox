{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "import urllib.parse\n",
    "from pprint import pprint as pp\n",
    "\n",
    "class TwitterAPI(object):\n",
    "    \"\"\"\n",
    "    TwitterAPI class allows the Connection to Twitter via OAuth\n",
    "    once you have registered with Twitter and receive the \n",
    "    necessary credentiials \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self): \n",
    "        consumer_key = 'bxZ2ypZgrxusqKvUGnlv1KNew'\n",
    "        consumer_secret = 'HiAk5tuYc657MNKSb8odAxnU33fm4nLAAXY10PkhM3uUxbP9XB'\n",
    "        access_token = '2983449373-pH31LSzmmrbgXrkZx08FWDnWqxNmWx74aMwLMt4'\n",
    "        access_secret = 'Q41AgD2NdZ6n2UQWh8YM6nMosCKLENWrfqh1oiUNhp4R9'\n",
    "     \n",
    "        self.consumer_key = consumer_key\n",
    "        self.consumer_secret = consumer_secret\n",
    "        self.access_token = access_token\n",
    "        self.access_secret = access_secret\n",
    "        self.auth = twitter.oauth.OAuth(access_token, access_secret, consumer_key, consumer_secret)\n",
    "        self.api = twitter.Twitter(auth=self.auth)\n",
    "\n",
    "    def searchTwitter(self, q, max_res=10,**kwargs):\n",
    "        search_results = self.api.search.tweets(q=q, count=10, **kwargs)\n",
    "        statuses = search_results['statuses']\n",
    "        max_results = min(1000, max_res)\n",
    "\n",
    "        for _ in range(10): \n",
    "            try:\n",
    "                next_results = search_results['search_metadata']['next_results']\n",
    "            except KeyError as e: \n",
    "                break\n",
    "\n",
    "            next_results = urllib.parse.parse_qsl(next_results[1:])\n",
    "            kwargs = dict(next_results)\n",
    "            search_results = self.api.search.tweets(**kwargs)\n",
    "            statuses += search_results['statuses']\n",
    "\n",
    "            if len(statuses) > max_results: \n",
    "                break\n",
    "        return statuses\n",
    "\n",
    "    def parseTweets(self, statuses):\n",
    "        return [ (status['id'], \n",
    "                  status['created_at'], \n",
    "                  status['user']['id'],\n",
    "                  status['user']['name'], \n",
    "                  status['text'], \n",
    "                  url['expanded_url']) \n",
    "                        for status in statuses \n",
    "                            for url in status['entities']['urls'] ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(843707766908702721,\n",
      "  'Mon Mar 20 06:16:21 +0000 2017',\n",
      "  4510060638,\n",
      "  'beginnershadoop',\n",
      "  'Apache-spark-machine-learning-tutorial\\n'\n",
      "  'https://t.co/rSNJckdHC8\\n'\n",
      "  '#apachespark #MachineLearning #maprblog',\n",
      "  'https://mapr.com/blog/apache-spark-machine-learning-tutorial/'),\n",
      " (843700441074614272,\n",
      "  'Mon Mar 20 05:47:15 +0000 2017',\n",
      "  104520454,\n",
      "  'alejandro vergara',\n",
      "  'RT @mapr: ETL and Interactive Analytics with @ApacheSpark and @ApacheDrill: '\n",
      "  'https://t.co/dxGTptjCYB https://t.co/1ccwh7ZLDo',\n",
      "  'http://bit.ly/2cbmaNJ'),\n",
      " (843700265807220737,\n",
      "  'Mon Mar 20 05:46:33 +0000 2017',\n",
      "  1977619399,\n",
      "  'pattern',\n",
      "  'RT @mapr: ETL and Interactive Analytics with @ApacheSpark and @ApacheDrill: '\n",
      "  'https://t.co/dxGTptjCYB https://t.co/1ccwh7ZLDo',\n",
      "  'http://bit.ly/2cbmaNJ'),\n",
      " (843685918808539136,\n",
      "  'Mon Mar 20 04:49:32 +0000 2017',\n",
      "  32317906,\n",
      "  'Amit Gairola',\n",
      "  'RT @gp_pulipaka: How to use SparkSession in #ApacheSpark 2.0. #BigData '\n",
      "  '#DataScience #Analytics \\n'\n",
      "  'https://t.co/MSWbdGaawr https://t.co/1n8sUL…',\n",
      "  'http://buff.ly/2nbWDJD'),\n",
      " (843685271753302016,\n",
      "  'Mon Mar 20 04:46:58 +0000 2017',\n",
      "  89203052,\n",
      "  'Suneet Garg',\n",
      "  'RT @gp_pulipaka: How to use SparkSession in #ApacheSpark 2.0. #BigData '\n",
      "  '#DataScience #Analytics \\n'\n",
      "  'https://t.co/MSWbdGaawr https://t.co/1n8sUL…',\n",
      "  'http://buff.ly/2nbWDJD'),\n",
      " (843678786776453120,\n",
      "  'Mon Mar 20 04:21:12 +0000 2017',\n",
      "  819490240327020544,\n",
      "  'Samael',\n",
      "  'RT @gp_pulipaka: How to use SparkSession in #ApacheSpark 2.0. #BigData '\n",
      "  '#DataScience #Analytics \\n'\n",
      "  'https://t.co/MSWbdGaawr https://t.co/1n8sUL…',\n",
      "  'http://buff.ly/2nbWDJD'),\n",
      " (843677696337084416,\n",
      "  'Mon Mar 20 04:16:52 +0000 2017',\n",
      "  1628349403,\n",
      "  'Murali Krishna',\n",
      "  'RT @gp_pulipaka: How to use SparkSession in #ApacheSpark 2.0. #BigData '\n",
      "  '#DataScience #Analytics \\n'\n",
      "  'https://t.co/MSWbdGaawr https://t.co/1n8sUL…',\n",
      "  'http://buff.ly/2nbWDJD'),\n",
      " (843676785329942528,\n",
      "  'Mon Mar 20 04:13:15 +0000 2017',\n",
      "  67333334,\n",
      "  'HealthIT Policy',\n",
      "  'RT @gp_pulipaka: How to use SparkSession in #ApacheSpark 2.0. #BigData '\n",
      "  '#DataScience #Analytics \\n'\n",
      "  'https://t.co/MSWbdGaawr https://t.co/1n8sUL…',\n",
      "  'http://buff.ly/2nbWDJD'),\n",
      " (843676068468875264,\n",
      "  'Mon Mar 20 04:10:24 +0000 2017',\n",
      "  4908885163,\n",
      "  'DeepSingularity',\n",
      "  'RT @gp_pulipaka: How to use SparkSession in #ApacheSpark 2.0. #BigData '\n",
      "  '#DataScience #Analytics \\n'\n",
      "  'https://t.co/MSWbdGaawr https://t.co/1n8sUL…',\n",
      "  'http://buff.ly/2nbWDJD'),\n",
      " (843674710714073089,\n",
      "  'Mon Mar 20 04:05:00 +0000 2017',\n",
      "  22329191,\n",
      "  'Dr Alan Beckles',\n",
      "  'RT @gp_pulipaka: How to use SparkSession in #ApacheSpark 2.0. #BigData '\n",
      "  '#DataScience #Analytics \\n'\n",
      "  'https://t.co/MSWbdGaawr https://t.co/1n8sUL…',\n",
      "  'http://buff.ly/2nbWDJD'),\n",
      " (843673607700144128,\n",
      "  'Mon Mar 20 04:00:37 +0000 2017',\n",
      "  4220691219,\n",
      "  'Philipp Buchholz',\n",
      "  'RT @java: Demo application to show how #Hazelcast and #ApacheSpark work '\n",
      "  'together @kittylyst \\n'\n",
      "  '\\n'\n",
      "  'https://t.co/gQUrRefC6V https://t.co/a286zPqN…',\n",
      "  'https://blog.hazelcast.com/interview-ben-evans/'),\n",
      " (843673060179759105,\n",
      "  'Mon Mar 20 03:58:26 +0000 2017',\n",
      "  2239946074,\n",
      "  'Manjunath',\n",
      "  'RT @gp_pulipaka: How to use SparkSession in #ApacheSpark 2.0. #BigData '\n",
      "  '#DataScience #Analytics \\n'\n",
      "  'https://t.co/MSWbdGaawr https://t.co/1n8sUL…',\n",
      "  'http://buff.ly/2nbWDJD'),\n",
      " (843672473791053824,\n",
      "  'Mon Mar 20 03:56:07 +0000 2017',\n",
      "  820822691846430720,\n",
      "  'Tech Now or Never',\n",
      "  'RT @mvrpl: #ScalaLang #apachespark #BigData #DataIngestion - '\n",
      "  'https://t.co/y7oPu9x40c',\n",
      "  'http://mvrpl.com.br/big-shipper'),\n",
      " (843672281054371841,\n",
      "  'Mon Mar 20 03:55:21 +0000 2017',\n",
      "  2956461358,\n",
      "  'Marcos Vinícius',\n",
      "  '#ScalaLang #apachespark #BigData #DataIngestion - https://t.co/y7oPu9x40c',\n",
      "  'http://mvrpl.com.br/big-shipper'),\n",
      " (843668513126518789,\n",
      "  'Mon Mar 20 03:40:22 +0000 2017',\n",
      "  104520454,\n",
      "  'alejandro vergara',\n",
      "  'RT @riz_emba: Excellent discussion by @IBM @apachespark_tc at #StrataHadoop '\n",
      "  'https://t.co/50bcPwBIij #deeplearning to #predict #cancer @Apac…',\n",
      "  'https://goo.gl/RRCDnK'),\n",
      " (843668321287323648,\n",
      "  'Mon Mar 20 03:39:37 +0000 2017',\n",
      "  1342641722,\n",
      "  'Riz EMBA',\n",
      "  'Excellent discussion by @IBM @apachespark_tc at #StrataHadoop '\n",
      "  'https://t.co/50bcPwBIij #deeplearning to #predict… https://t.co/X5hDlausfr',\n",
      "  'https://goo.gl/RRCDnK'),\n",
      " (843668321287323648,\n",
      "  'Mon Mar 20 03:39:37 +0000 2017',\n",
      "  1342641722,\n",
      "  'Riz EMBA',\n",
      "  'Excellent discussion by @IBM @apachespark_tc at #StrataHadoop '\n",
      "  'https://t.co/50bcPwBIij #deeplearning to #predict… https://t.co/X5hDlausfr',\n",
      "  'https://twitter.com/i/web/status/843668321287323648'),\n",
      " (843666259627655170,\n",
      "  'Mon Mar 20 03:31:25 +0000 2017',\n",
      "  511740616,\n",
      "  'BIconnections',\n",
      "  'RT @gp_pulipaka: How to use SparkSession in #ApacheSpark 2.0. #BigData '\n",
      "  '#DataScience #Analytics \\n'\n",
      "  'https://t.co/MSWbdGaawr https://t.co/1n8sUL…',\n",
      "  'http://buff.ly/2nbWDJD'),\n",
      " (843665980052197377,\n",
      "  'Mon Mar 20 03:30:18 +0000 2017',\n",
      "  98882777,\n",
      "  'Fabian Luna',\n",
      "  'RT @gp_pulipaka: How to use SparkSession in #ApacheSpark 2.0. #BigData '\n",
      "  '#DataScience #Analytics \\n'\n",
      "  'https://t.co/MSWbdGaawr https://t.co/1n8sUL…',\n",
      "  'http://buff.ly/2nbWDJD'),\n",
      " (843665474286112768,\n",
      "  'Mon Mar 20 03:28:18 +0000 2017',\n",
      "  4263007693,\n",
      "  'Dr. GP Pulipaka',\n",
      "  'RT @gp_pulipaka: How to use SparkSession in #ApacheSpark 2.0. #BigData '\n",
      "  '#DataScience #Analytics \\n'\n",
      "  'https://t.co/MSWbdGaawr https://t.co/1n8sUL…',\n",
      "  'http://buff.ly/2nbWDJD'),\n",
      " (843664993065320449,\n",
      "  'Mon Mar 20 03:26:23 +0000 2017',\n",
      "  104520454,\n",
      "  'alejandro vergara',\n",
      "  'RT @gp_pulipaka: How to use SparkSession in #ApacheSpark 2.0. #BigData '\n",
      "  '#DataScience #Analytics \\n'\n",
      "  'https://t.co/MSWbdGaawr https://t.co/1n8sUL…',\n",
      "  'http://buff.ly/2nbWDJD')]\n"
     ]
    }
   ],
   "source": [
    "t= TwitterAPI()\n",
    "q=\"ApacheSpark\"\n",
    "tsearch = t.searchTwitter(q)\n",
    "len(tsearch)\n",
    "tparse = t.parseTweets(tsearch)\n",
    "pp(tparse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
